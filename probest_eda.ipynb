{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c37dfaa",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "\n",
    "Exploratory Data Analysis (EDA) é uma etapa fundamental no processo de Ciência de Dados, cujo objetivo é compreender melhor os dados antes da aplicação de modelos ou técnicas mais avançadas. Durante o EDA, são utilizadas técnicas estatísticas, matemáticas e de visualização para:\n",
    "\n",
    "* **Explorar a estrutura dos dados**: identificar tipos de variáveis, distribuições, valores ausentes e outliers.\n",
    "* **Resumir características principais**: obter medidas descritivas como média, mediana, variância e correlação.\n",
    "* **Visualizar padrões**: usar gráficos (histogramas, boxplots, scatter plots, heatmaps, etc.) para detectar tendências, relações e possíveis anomalias.\n",
    "* **Gerar hipóteses iniciais**: levantar insights que podem guiar as próximas etapas da análise ou do desenvolvimento de modelos preditivos.\n",
    "\n",
    "O EDA não apenas garante uma compreensão mais profunda do conjunto de dados, mas também ajuda a evitar erros e a tomar decisões mais embasadas em todo o ciclo de análise.\n",
    "\n",
    "Instalar os pacotes necessários:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc721204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opendatasets in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.1.22)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.3.1)\n",
      "Requirement already satisfied: kaggle in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.7.4.5)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opendatasets) (4.67.1)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from opendatasets) (8.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: bleach in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (6.2.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (2025.8.3)\n",
      "Requirement already satisfied: charset-normalizer in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (3.4.3)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (3.10)\n",
      "Requirement already satisfied: protobuf in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (6.32.1)\n",
      "Requirement already satisfied: python-slugify in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (2.32.5)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (80.9.0)\n",
      "Requirement already satisfied: six>=1.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (1.17.0)\n",
      "Requirement already satisfied: text-unidecode in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (1.3)\n",
      "Requirement already satisfied: urllib3>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (2.5.0)\n",
      "Requirement already satisfied: webencodings in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from kaggle) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opendatasets pandas kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c847b",
   "metadata": {},
   "source": [
    "## 1. Kaggle CLI – Instalação e Uso\n",
    "\n",
    "O **Kaggle CLI** permite interagir com a plataforma Kaggle diretamente pelo terminal, facilitando o download de datasets, submissão de competições e gerenciamento de kernels.\n",
    "\n",
    "### 1.1 Pré-requisitos\n",
    "\n",
    "* Python 3.7+ instalado\n",
    "* `pip` configurado\n",
    "* Conta no [Kaggle](https://www.kaggle.com)\n",
    "\n",
    "### 1.2 Instalação\n",
    "\n",
    "```bash\n",
    "pip install kaggle\n",
    "```\n",
    "\n",
    "Verifique a instalação:\n",
    "\n",
    "```bash\n",
    "kaggle --version\n",
    "```\n",
    "\n",
    "### 1.3 Configuração da API\n",
    "\n",
    "1. Acesse [Kaggle – Account Settings](https://www.kaggle.com/account).\n",
    "2. Vá em **API > Create New API Token**.\n",
    "3. Um arquivo chamado `kaggle.json` será baixado (contendo suas credenciais).\n",
    "4. Coloque o arquivo na pasta correta:\n",
    "\n",
    "   * Linux/MacOS:\n",
    "\n",
    "     ```bash\n",
    "     mkdir -p ~/.kaggle\n",
    "     mv ~/Downloads/kaggle.json ~/.kaggle/\n",
    "     chmod 600 ~/.kaggle/kaggle.json\n",
    "     ```\n",
    "   * Windows:\n",
    "     Coloque o arquivo em:\n",
    "\n",
    "     ```\n",
    "     C:\\Users\\<SeuUsuario>\\.kaggle\\kaggle.json\n",
    "     ```\n",
    "\n",
    "### 1.4 Comandos Básicos\n",
    "\n",
    "#### Listar competições\n",
    "\n",
    "```bash\n",
    "kaggle competitions list\n",
    "```\n",
    "\n",
    "#### Fazer download de dataset\n",
    "\n",
    "```bash\n",
    "kaggle datasets download -d <username>/<dataset-name>\n",
    "```\n",
    "\n",
    "Exemplo:\n",
    "\n",
    "```bash\n",
    "kaggle datasets download -d jsrojas/labeled-network-traffic-flows-114-applications --path datasets\n",
    "```\n",
    "\n",
    "#### Descompactar o dataset baixado\n",
    "\n",
    "```bash\n",
    "unzip datasets/labeled-network-traffic-flows-114-applications.zip -d ./datasets\n",
    "```\n",
    "\n",
    "#### Participar de competições\n",
    "\n",
    "Baixar os dados de uma competição:\n",
    "\n",
    "```bash\n",
    "kaggle competitions download -c <competition-name>\n",
    "```\n",
    "\n",
    "Enviar uma submissão:\n",
    "\n",
    "```bash\n",
    "kaggle competitions submit -c <competition-name> -f submission.csv -m \"Mensagem da submissão\"\n",
    "```\n",
    "\n",
    "### 1.5 Dicas Úteis\n",
    "\n",
    "* Sempre mantenha o arquivo `kaggle.json` **em local seguro**, pois ele contém sua chave de API.\n",
    "* É possível integrar o Kaggle CLI a notebooks e pipelines automatizados (ex.: Google Colab, Jupyter, scripts de ETL).\n",
    "* Para ver todos os comandos disponíveis:\n",
    "\n",
    "  ```bash\n",
    "  kaggle --help\n",
    "  ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd0857c",
   "metadata": {},
   "source": [
    "## 2. Roteiro de EDA na Prática\n",
    "\n",
    "## 2.1 Introdução\n",
    "\n",
    "* Explicar o que é EDA e sua importância.\n",
    "* Apresentar o dataset: *Labeled Network Traffic Flows*.\n",
    "\n",
    "  * Origem: tráfego de rede rotulado (ataques vs. normal).\n",
    "  * Objetivo: identificar padrões e diferenças entre classes.\n",
    "\n",
    "\n",
    "## 2.2 Preparação dos Dados\n",
    "\n",
    "* Importar bibliotecas (`pandas`, `numpy`, `matplotlib`, `seaborn`).\n",
    "* Carregar o dataset com `pd.read_csv()`.\n",
    "* Exibir informações iniciais:\n",
    "\n",
    "  * `.head()`, `.info()`, `.describe()`.\n",
    "  * Tipos de dados e valores ausentes.\n",
    "\n",
    "\n",
    "## 2.3 Análise Univariada\n",
    "\n",
    "* Verificar a distribuição das classes (ex.: tráfego normal vs. ataque).\n",
    "* Usar gráficos de barras e `value_counts()` para contar instâncias por classe.\n",
    "* Explorar estatísticas descritivas (média, mediana, desvio-padrão).\n",
    "\n",
    "\n",
    "## 2.4 Análise Bivariada\n",
    "\n",
    "* Explorar correlações entre variáveis numéricas (heatmap de `seaborn`).\n",
    "* Relacionar características específicas (ex.: duração, bytes enviados/recebidos) com a classe de tráfego.\n",
    "* Utilizar scatter plots e boxplots para observar diferenças.\n",
    "\n",
    "\n",
    "## 2.5 Análise de Outliers\n",
    "\n",
    "* Verificar variáveis contínuas com boxplots.\n",
    "* Discutir a presença de valores extremos e seu impacto na análise.\n",
    "\n",
    "\n",
    "## 2.6 Insights Iniciais\n",
    "\n",
    "* Quais variáveis melhor diferenciam tráfego normal de tráfego malicioso?\n",
    "* Há desequilíbrio de classes? (importante para machine learning).\n",
    "* Quais variáveis parecem redundantes ou pouco informativas?\n",
    "\n",
    "\n",
    "## 2.7 Conclusão\n",
    "\n",
    "* Destacar como o EDA ajuda a entender o dataset antes da modelagem.\n",
    "* Apontar próximos passos: pré-processamento, seleção de features e aplicação de algoritmos de ML.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c550108a",
   "metadata": {},
   "source": [
    "### Preparação do Ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e75b812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Preparação do Ambiente\n",
    "# ========================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4bcd0b",
   "metadata": {},
   "source": [
    "### Configurar o estilo e carregar o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5329e17f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'datasets/Unicauca-dataset-April-June-2019-Network-flows.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m plt.rcParams[\u001b[33m\"\u001b[39m\u001b[33mfigure.figsize\u001b[39m\u001b[33m\"\u001b[39m] = (\u001b[32m10\u001b[39m, \u001b[32m6\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Carregar dataset (ajuste o caminho conforme necessário)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdatasets/Unicauca-dataset-April-June-2019-Network-flows.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'datasets/Unicauca-dataset-April-June-2019-Network-flows.csv'"
     ]
    }
   ],
   "source": [
    "# Configurações de estilo\n",
    "sns.set(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "\n",
    "# Carregar dataset (ajuste o caminho conforme necessário)\n",
    "df = pd.read_csv(\"datasets/Unicauca-dataset-April-June-2019-Network-flows.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27afca1",
   "metadata": {},
   "source": [
    "### Exploração inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519be78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Exploração Inicial\n",
    "# ========================================\n",
    "print(\"Dimensões do dataset:\", df.shape)\n",
    "print(\"\\nTipos de dados:\")\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "print(\"\\nVisualizando as 5 primeiras linhas:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nResumo estatístico:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Verificar valores ausentes\n",
    "print(\"\\nValores ausentes por coluna:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ========================================\n",
    "# Análise Univariada\n",
    "# ========================================\n",
    "# Distribuição das classes\n",
    "print(\"\\nDistribuição das classes:\")\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "sns.countplot(data=df, x=\"Label\")\n",
    "plt.title(\"Distribuição das Classes (Normal vs Ataque)\")\n",
    "plt.show()\n",
    "\n",
    "# Exemplo: distribuição de uma variável numérica\n",
    "sns.histplot(df['Duration'], bins=50, kde=True)\n",
    "plt.title(\"Distribuição da variável Duration\")\n",
    "plt.show()\n",
    "\n",
    "# ========================================\n",
    "# Análise Bivariada\n",
    "# ========================================\n",
    "# Correlação entre variáveis numéricas\n",
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, cmap=\"coolwarm\", annot=False)\n",
    "plt.title(\"Mapa de Correlação\")\n",
    "plt.show()\n",
    "\n",
    "# Relação entre Duration e Label\n",
    "sns.boxplot(data=df, x=\"Label\", y=\"Duration\")\n",
    "plt.title(\"Comparação da variável Duration por Classe\")\n",
    "plt.show()\n",
    "\n",
    "# Relação entre TotPkts (total de pacotes) e TotBytes (total de bytes)\n",
    "sns.scatterplot(data=df, x=\"TotPkts\", y=\"TotBytes\", hue=\"Label\", alpha=0.6)\n",
    "plt.title(\"TotPkts vs TotBytes (com rótulo)\")\n",
    "plt.show()\n",
    "\n",
    "# ========================================\n",
    "# Outliers\n",
    "# ========================================\n",
    "sns.boxplot(x=df[\"TotBytes\"])\n",
    "plt.title(\"Outliers em TotBytes\")\n",
    "plt.show()\n",
    "\n",
    "# ========================================\n",
    "# Insights\n",
    "# ========================================\n",
    "# Exemplo de verificação de desbalanceamento de classes\n",
    "class_counts = df['Label'].value_counts(normalize=True)\n",
    "print(\"\\nProporção das classes (%):\")\n",
    "print(class_counts * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
